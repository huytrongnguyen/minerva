/*
 * This Scala source file was generated by the Gradle 'init' task.
 */
package minerva

import org.apache.spark.sql.{SparkSession, DataFrame}
import org.apache.spark.sql.types._

object App {
  def main(args: Array[String]): Unit = {
    // Initialize SparkSession with MinIO configurations
    val spark = SparkSession.builder()
      .appName("Minerva")
      .master("local[*]") // Use local mode for testing; adjust for cluster
      .config("spark.hadoop.fs.s3a.endpoint", "http://minio:9000")
      .config("spark.hadoop.fs.s3a.access.key", "minioadmin")
      .config("spark.hadoop.fs.s3a.secret.key", "minioadmin")
      .config("spark.hadoop.fs.s3a.path.style.access", "true")
      .config("spark.hadoop.fs.s3a.impl", "org.apache.hadoop.fs.s3a.S3AFileSystem")
      .config("spark.hadoop.fs.s3a.connection.ssl.enabled", "false")
      .getOrCreate()

    // Sample data
    val data = Seq(("Alice", 25), ("Bob", 30), ("Cathy", 28))
    val df = spark.createDataFrame(data).toDF("name", "age")

    // Write to MinIO
    df.write
      .mode("overwrite")
      .parquet("s3a://spark-bucket/output")

    // Read from MinIO
    val readDf = spark.read.parquet("s3a://spark-bucket/output")
    readDf.show()

    // Stop SparkSession
    spark.stop()
  }
}

# Roadmap

From zero to a fully operational real-time LTV & campaign-optimization platform inside a game studio. **2026 fully focused on LTV prediction mastery** (build, refine, and prove the core engine for accurate forecasts), with **2027 shifting to campaign optimization** (full automation, scaling, and externalisation built on the trusted LTV base). This keeps momentum with a small overlap (e.g., manual recommendations in late 2026 to prep for 2027 automation).

| Year & Phase | Timeline         | Primary Focus & Goal                                                                 | Core Deliverables (Aligned with Initiatives)                                                                                                                              | Success KPIs (SMART-Aligned) |
|--------------|------------------|--------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------------|
| **2026: LTV Prediction Mastery**<br>Phase A: Foundations | Jan – Mar 2026   | Build reliable data flow + simulation for testing                                    | • Kafka + SDKs + Bronze/Silver layers<br>• Simulation App v2 (1M players, ThinkingData/AppsFlyer sandbox)<br>• Basic Postgres mart + events explorer dashboard | 100 % games/sim sending events ≤ 5 min latency; 99.9 % uptime |
| Phase B: LTV Core | Apr – Jun 2026   | Accurate pLTV models + first dashboards                                              | • XGBoost/Survival models (D7/D30/D180 LTV)<br>• Feature engineering (D0–D7 signals)<br>• Model validation dashboard + nightly inference | ≥ 85 % pLTV D30 accuracy (MAPE ≤ 15 %); Model used in weekly UA meetings |
| Phase C: LTV Validation & Manual Wins | Jul – Dec 2026   | Prove LTV in real-world + manual ROAS gains                                          | • Cohort/LTV waterfalls in Tableau<br>• Manual recommendations (e.g., "shift budget to high-pLTV channels")<br>• Simulation v4 for back-testing + scenario planning | ≥ 15 % manual ROAS uplift vs 2025; 80 % team adoption; Simulation runs full quarter in <1 day |
| **2027: Campaign Optimization Mastery**<br>Phase D: Automation Basics | Jan – Apr 2027   | Close the loop with rule-based automation                                            | • ROAS engine + auto-pause/scale scripts (Meta/Google/TikTok)<br>• Lookalike exports + bid multipliers<br>• Churn alerts + whale rescue | ≥ 70 % decisions automated; ≥ 25 % ROAS uplift proven |
| Phase E: Advanced Optimization | May – Aug 2027   | AI-driven bidding + dynamic personalization                                          | • RL/Bandit optimizer + dynamic pricing<br>• Generative LiveOps (auto-offers/events)<br>• Self-service cohort builder + anomaly detection | +18 % ARPU from personalization; ≥ 30 % total ROAS uplift vs 2025 |
| Phase F: Expansion & Licensing | Sep – Dec 2027   | Scale to multi-studio + commercialise                                                | • Cross-studio federation (player 360 across 20+ titles)<br>• White-label launch (5 external studios)<br>• Simulation v5 as "sandbox product" | $3–8 M ARR from licensing; Supports 10× volume; Used by 5+ external partners |

## Detailed Phase Plan

- **2026 = LTV Prediction Mastery** (accurate, trustworthy forecasts + manual wins)  
- **2027 = Campaign Optimization Mastery** (full automation + scaling)

| Phase | Timeline          | Primary Goal                                                                 | Key Outcomes by End of Phase                                                                                                              | Total Effort (person-days) |
|-------|-------------------|------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------|----------------------------|
| A     | Jan – Mar 2026    | Foundations                                                                  | Reliable real-time pipeline + Simulation App generating perfect testing data                                                              | ~170                       |
| B     | Apr – Jun 2026    | LTV Core Model                                                               | ≥ 85 % accurate pLTV D30 model + nightly inference                                                                                        | ~200                       |
| C     | Jul – Dec 2026    | LTV Validation & Manual Wins                                                 | Model proven on real data + ≥ 15 % manual ROAS uplift via dashboards                                                                       | ~250                       |
| D     | Jan – Apr 2027    | Automation Basics                                                            | Rule-based auto-pause/scale + lookalikes live → ≥ 70 % decisions automated                                                                | ~220                       |
| E     | May – Aug 2027    | Advanced Optimization                                                        | RL bidding + dynamic personalization → +18 % ARPU + ≥ 30 % ROAS uplift                                                                    | ~280                       |
| F     | Sep – Dec 2027    | Expansion & Licensing                                                        | Cross-studio federation + white-label launch → $3–8 M ARR from licensing                                                                  | ~200                       |

#### Phase A – Foundations (Jan – Mar 2026)

- **Goal**: Build a reliable, real-time data flow + simulation environment capable of generating perfect testing data.  
By end of March 2026: 100 % of live games + Simulation App sending identical events into the pipeline with ≤ 5 min latency.

| Week | Dates 2026      | Task ID | Task (Jira title)                                                                 | Owner                     | Effort (person-days) | Acceptance Criteria (DoD) – Friday Demo                                                                                                                                                    | Deliverable / Proof                                      |
|------|-----------------|---------|-----------------------------------------------------------------------------------|---------------------------|----------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------|
| 1–2  | 05–16 Jan       | A-01    | Deploy production Kafka cluster + monitoring + alerting                           | Lead DE                   | 10                   | 3–5 node cluster live, Grafana dashboards, Slack alerts on lag >10 s, 1 M msg/day test passes                                                                                           | Grafana link + test script                               |
| 1–3  | 05–23 Jan       | A-02    | Integrate SDKs into all live games (Unity + Unreal)                               | Game Dev teams + DE       | 15                   | All titles sending real events to Kafka (even if throttled to 10 %) — visible in Bronze next to simulated events                                                                        | Real events in Kafka UI                                  |
| 2–4  | 12–30 Jan       | A-03    | Build Simulation App MVP (ASP.NET Core + React + SignalR + Postgres)              | Full-stack dev            | 20                   | React UI: “Start Simulation” → creates 1 k fake players → events visible live in browser log + Postgres                                                                                  | Local + staging app running, video demo                   |
| 3–5  | 19 Jan – 06 Feb | A-04    | Simulation App → Kafka producer (Avro serialized, 50+ event types)                | Full-stack + DE           | 18                   | 100 k simulated events hit Kafka topics within minutes — schema enforced, no losses                                                                                                  | Kafka UI count + schema registry screenshot              |
| 4–6  | 26 Jan – 13 Feb | A-05    | Bronze & Silver Delta tables on MinIO (partitioned, schema evolution)             | DE                        | 20                   | Spark queries show real + simulated events side-by-side in bronze.game_events and silver.player_events — daily partitioning + VACUUM DAG running                                          | Spark SQL demo + Airflow DAG screenshot                  |
| 5–7  | 02–20 Feb       | A-06    | Player archetypes & probabilistic behavior engine (casual/core/whale)             | DS + Full-stack           | 22                   | 4 archetypes with realistic session frequency, spend probability, geo/device spoofing — 10 k concurrent players run 24 h without crash                                                   | Config JSON + 24 h load test report                      |
| 6–8  | 09–27 Feb       | A-07    | Basic Postgres mart (player_analytics_daily) + “Events Explorer” Tableau dashboard| Analyst + DE              | 18                   | Anyone can open Tableau → filter by game/date/channel → see real + simulated events + basic counts/retention                                                                             | Published Tableau link + 20 active users                 |
| 7–9  | 16 Feb – 06 Mar | A-08    | ThinkingData sandbox integration (sim events → ThinkingData dashboard)            | Full-stack + DS           | 15                   | Simulated cohorts, funnels, retention visible in real ThinkingData UI — matches internal mart                                                                                          | ThinkingData screenshot + side-by-side comparison        |
| 8–10 | 23 Feb – 13 Mar | A-09    | Data quality + governance basics (lineage, null checks, GDPR hashing)             | DE + Legal                | 12                   | Airflow DAGs alert on >5 % nulls in key fields; player_id hashed in Silver; lineage documented                                                                                         | Alert log + Confluence lineage page                      |
| 9–11 | 02–20 Mar       | A-10    | Phase A retrospective + leadership demo                                           | All                       | 8                    | Leadership sees real + 1 M simulated players generating cohorts in real-time — sign-off for Phase B                                                                                      | Recording + signed go/no-go                              |
| 11   | 21–27 Mar       | A-11    | Buffer / bug-fix / documentation week                                             | Whole team                | 10                   | 100 % DoD green, full Confluence docs, repo clean, hand-off deck ready                                                                                                                 | Phase A officially closed                                |

#### Phase B – LTV Core Model (Apr – Jun 2026)

**Goal**: Build, train, and ship a production-grade pLTV model with ≥ 85 % Day-30 accuracy.  
By end of June 2026: Model is running nightly, predictions are in the mart, and UA/Product teams are using them for manual decisions.

| Week | Dates 2026       | Task ID | Task (Jira title)                                                                 | Owner                     | Effort (person-days) | Acceptance Criteria (DoD) – Friday Demo                                                                                                                                                    | Deliverable / Proof                                      |
|------|------------------|---------|-----------------------------------------------------------------------------------|---------------------------|----------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------|
| 12–13| 27 Mar – 10 Apr  | B-01    | Finalize 60+ D0–D7 predictive feature catalogue (retention, spend velocity, etc.) | DS + DE                   | 12                   | Confluence page with feature definitions, SQL views in Silver layer, prioritized list for modeling                                                                                       | Feature catalog doc + Spark query demo                   |
| 13–15| 10 Apr – 24 Apr  | B-02    | Generate perfect 24-month simulated training dataset (via Sim App)                | DS + Full-stack dev       | 25                   | 5–10 M simulated players, 400 M+ events, balanced whales/churners, exact schema match — stored in MinIO for training                                                                    | Dataset checksum + sample cohort in ThinkingData          |
| 14–17| 17 Apr – 15 May  | B-03    | Train & tune XGBoost + Survival Analysis models (D7/D30/D180 LTV)                 | DS                        | 40                   | ≥ 84 % MAPE on simulated hold-out, ≥ 82 % on real Jan–Mar 2026 data; feature importance report; Optuna hyperparam logs                                                                   | MLflow run IDs + back-test notebook                      |
| 16–18| 01 May – 22 May  | B-04    | Model packaging + nightly inference Spark job                                      | DE + DS                   | 25                   | Model registered in MLflow, Spark job runs 03:00 UTC daily, UPSERT predictions into mart.player_analytics_daily (player_id + acquisition_date)                                               | Airflow DAG log + sample predicted rows                  |
| 17–19| 08 May – 05 Jun  | B-05    | Model performance monitoring + drift detection dashboard                          | DS + Analyst              | 20                   | Tableau worksheet: daily MAPE vs actuals, PSI drift score, Slack alert if accuracy drops >5 % or drift >0.2                                                                                | Live monitoring dashboard + test alert                   |
| 18–20| 22 May – 12 Jun  | B-06    | Simulation App v3 integration for model validation loops                          | Full-stack + DS           | 22                   | “Validate Model” button: run 100 k new simulated players → 30 simulated days → auto-compare predicted vs actual LTV                                                                       | Video demo + accuracy report from sim run                |
| 19–21| 29 May – 19 Jun  | B-07    | Initial LTV waterfall & cohort heatmaps in Tableau (manual decision support)      | Analyst                   | 20                   | UA team can slice LTV by channel/country/device → replace basic Excel views                                                                                                                 | Published workbook + UA feedback session                 |
| 20–21| 12–26 Jun        | B-08    | Final model validation on real data + leadership sign-off                         | DS + UA + Finance         | 15                   | ≥ 85 % Day-30 accuracy on Apr–Jun real cohorts; finance signs off “trustworthy for budgeting”                                                                                            | Signed validation report + champagne                     |
| 21   | 26–30 Jun        | B-09    | Phase B retrospective + hand-off to Phase C                                       | All                       | 8                    | Retro board + lessons learned; Phase C kick-off deck ready                                                                                                                                 | Recording + sign-off                                     |

#### Phase C – LTV Validation & Manual Wins (Jul – Dec 2026)

**Goal**: Prove the LTV model on real-world data, drive ≥ 15 % ROAS uplift through **manual** decisions (dashboards + recommendations), and prepare for 2027 automation.  
By end of December 2026: Model is battle-tested, UA/Product teams rely on it daily (no more Excel), and measurable revenue impact is finance-verified.

| Week | Dates 2026       | Task ID | Task (Jira title)                                                                 | Owner                     | Effort (person-days) | Acceptance Criteria (DoD) – Friday Demo                                                                                                                                                    | Deliverable / Proof                                      |
|------|------------------|---------|-----------------------------------------------------------------------------------|---------------------------|----------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------|
| 22–24| 03–24 Jul        | C-01    | Build full LTV waterfall, cohort heatmap, and AARRR funnel dashboards             | Analyst + DS              | 30                   | UA replaces all Excel cohort sheets; dashboards show predicted vs actual LTV by channel/country/device/geo                                                                                 | Published Tableau workbook + UA sign-off                 |
| 23–26| 10 Jul – 07 Aug  | C-02    | Manual ROAS recommendation engine (e.g., "Scale TikTok IN +30 %, Pause Meta BR")  | UA + DS                   | 35                   | Weekly recommendation deck auto-generated from model; UA acts on ≥ 70 % of top recommendations                                                                                            | First manual budget shift + tracking sheet               |
| 25–28| 24 Jul – 21 Aug  | C-03    | A/B testing framework for manual decisions (50 % model-guided vs 50 % old way)     | UA + Finance              | 40                   | Clear A/B cohorts defined; ROAS difference measured monthly; early signals show ≥ 10 % uplift in model-guided group                                                                       | A/B setup doc + monthly report                           |
| 27–30| 14 Aug – 11 Sep  | C-04    | Simulation App v4 – Advanced scenario planning & back-testing                     | Full-stack + DS           | 45                   | Run full simulated quarter in <24 h; validate "what-if" scenarios (e.g., "what if we scaled bad channel?") — proves model would have saved $X                                            | Monte-Carlo report + video demo                          |
| 29–33| 04 Sep – 02 Oct  | C-05    | Deep-dive analytics: whale identification, churn signals, segment deep dives      | DS + LiveOps              | 40                   | "Whale Watch" list + churn risk score in dashboard; first manual whale rescue offers sent (e.g., VIP bundles)                                                                              | Slack list + early rescue revenue                        |
| 31–35| 18 Sep – 16 Oct  | C-06    | Cross-validation on summer cohorts + model retraining pipeline                    | DS                        | 35                   | Model refreshed monthly with new actuals; accuracy stable ≥ 85 % despite seasonal shifts                                                                                                 | Retrain log + accuracy trend chart                       |
| 34–38| 09 Oct – 06 Nov  | C-07    | Studio-wide adoption push (training sessions, documentation, feedback loops)      | All + HR                  | 30                   | ≥ 80 % weekly active users in dashboards; zero Excel cohort reports remaining; feedback survey >8/10                                                                                      | Usage analytics + survey results                         |
| 37–41| 30 Oct – 27 Nov  | C-08    | Final 2026 ROAS uplift measurement + manual wins report                           | Finance + UA              | 35                   | ≥ 15 % blended paid ROAS uplift vs 2025 baseline (finance-verified); $X incremental revenue attributed to manual model use                                                                  | Signed ROI report + leadership presentation              |
| 40–43| 20 Nov – 18 Dec  | C-09    | Prep for 2027 automation (rule definitions, API wrappers, threshold tuning)       | DE + UA                   | 30                   | Draft rules ready (e.g., "pause if pROAS <0.7 for 48 h"); API wrappers tested in sandbox                                                                                                 | Rule doc + sandbox test log                              |
| 43–44| 18–31 Dec        | C-10    | Phase C retrospective + 2026 celebration + 2027 kick-off                          | All                       | 15                   | Retro + lessons learned; full 2026 impact deck; Phase D planning complete                                                                                                                  | Recording + champagne + signed 2027 plan                 |

#### Phase D – Automation Basics (Jan – Apr 2027)

**Goal**: Turn trusted LTV predictions into **rule-based automation** — close the loop with ad platforms for auto-pause/scale/bid adjustments.  
By end of April 2027: ≥ 70 % of paid campaign decisions automated, ≥ 25 % ROAS uplift vs 2026 baseline proven.

| Week | Dates 2027       | Task ID | Task (Jira title)                                                                 | Owner                     | Effort (person-days) | Acceptance Criteria (DoD) – Friday Demo                                                                                                                                                    | Deliverable / Proof                                      |
|------|------------------|---------|-----------------------------------------------------------------------------------|---------------------------|----------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------|
| 1–3  | 04–22 Jan        | D-01    | Full ROAS & payback calculation engine (predicted + actual)                       | DS + DE                   | 25                   | roas_d7/d30, payback_days columns match AppsFlyer within ±2 %; live in Postgres mart                                                                                                       | Side-by-side comparison table                            |
| 2–5  | 11 Jan – 08 Feb  | D-02    | Campaign dimension + attribution enrichment (adset/creative/cost from AppsFlyer)   | DE + UA                   | 30                   | Every player has full campaign hierarchy + install_cost_usd in mart; backfilled for last 12 months                                                                                         | Query demo + historical accuracy report                  |
| 4–7  | 25 Jan – 22 Feb  | D-03    | Rule engine design + threshold tuning (e.g., "pause if pROAS_d30 < 0.7 for 48 h") | UA + DS                   | 35                   | Rule document signed off by UA; thresholds validated on 2026 data (would have saved $X if live)                                                                                            | Rule matrix + back-test savings estimate                 |
| 6–9  | 08 Feb – 08 Mar  | D-04    | Auto-pause/scale API wrappers (Meta, Google, TikTok, ironSource)                  | DE                        | 45                   | Sandbox tests succeed: pause, scale, resume campaigns via API; manual override button in internal UI                                                                                        | Sandbox log + first test pause/resume                    |
| 8–11 | 22 Feb – 22 Mar  | D-05    | Production rollout of rule-based automation (start with 30 % of spend)            | DE + UA                   | 40                   | First real auto-pause happens; audit log shows actions; safety rails (daily spend cap, human approval for >$50 k changes)                                                                   | Live action log + safety demo                            |
| 10–12| 15 Mar – 05 Apr  | D-06    | Lookalike audience auto-export + basic bid multipliers                           | DE + UA                   | 30                   | High-pLTV segments (top 5–10 %) exported every 6 h → new lookalikes created in ad platforms; multiplier rules applied (e.g., +50 % bid for top decile)                                          | Ad platform screenshot of auto-lookalikes                |
| 11–13| 29 Mar – 19 Apr  | D-07    | Automation monitoring dashboard + rollback procedures                             | Analyst + DE              | 25                   | Tableau view: actions taken, ROAS impact per campaign; one-click rollback; alerts on anomalies                                                                                            | Live monitoring + test rollback                          |
| 12–14| 05–26 Apr        | D-08    | Final ROAS uplift measurement + Phase D sign-off                                  | Finance + UA + Leadership | 30                   | ≥ 25 % blended paid ROAS uplift vs 2026 baseline (finance-verified); ≥ 70 % of eligible decisions automated                                                                                | Signed ROI report + champagne                            |
| 14   | 26–30 Apr        | D-09    | Phase D retrospective + hand-off to Phase E                                       | All                       | 10                   | Retro + lessons; Phase E (advanced optimization) kick-off deck ready                                                                                                                       | Recording + sign-off                                     |

#### Phase E – Advanced Optimization (May – Aug 2027)

**Goal**: Evolve from rule-based to **AI-driven optimization** — introduce reinforcement learning, dynamic pricing, and generative LiveOps for maximum uplift.  
By end of August 2027: +18 % ARPU from personalization, ≥ 30 % total ROAS uplift vs 2025 baseline, platform fully self-improving.

| Week | Dates 2027       | Task ID | Task (Jira title)                                                                 | Owner                     | Effort (person-days) | Acceptance Criteria (DoD) – Friday Demo                                                                                                                                                    | Deliverable / Proof                                      |
|------|------------------|---------|-----------------------------------------------------------------------------------|---------------------------|----------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------|
| 13–15| 02–20 May        | E-01    | Design RL/multi-armed bandit bid optimizer architecture                           | DS + Senior DE            | 25                   | Architecture doc signed off; proof-of-concept on simulated traffic shows ≥ 8 % better ROAS than rule-based                                                                                 | Sim back-test report + architecture diagram              |
| 14–18| 09 May – 13 Jun  | E-02    | Train & deploy RL agent (Ray RLlib or custom) on historical + simulated data      | DS                        | 50                   | Agent beats rule-based by ≥ 10 % in offline tests; online shadow mode running on 20 % of spend                                                                                           | Offline evaluation + shadow log                          |
| 16–20| 23 May – 20 Jun  | E-03    | Live rollout of RL bidding (gradual ramp to 100 % of spend)                       | DE + UA                   | 45                   | Agent live on all channels; safety rails (max bid cap, human override); first week shows positive uplift                                                                                  | Live action log + weekly ROAS comparison                 |
| 18–22| 06 Jun – 04 Jul  | E-04    | Dynamic pricing engine for IAPs (prices adjust hourly by country + player value)   | DS + Monetization         | 50                   | Prices change automatically (e.g., +20 % for whales, -15 % for churn-risk); A/B test framework live                                                                                       | Pricing API demo + first dynamic price change            |
| 20–24| 20 Jun – 18 Jul  | E-05    | Generative LiveOps engine (auto-create events/offers using pLTV + churn signals)   | DS + LiveOps              | 55                   | AI generates profitable event ideas (e.g., "Weekend Whale Boost"); top 3 deployed weekly; ≥ 15 % revenue lift in test titles                                                                | Generated event doc + revenue uplift report              |
| 22–26| 04 Jul – 01 Aug  | E-06    | Advanced churn rescue + personalized re-engagement flows                          | LiveOps + DE              | 45                   | Daily personalized pushes/offers to at-risk players; ≥ 60 % rescue rate on whales; integrated with Braze/OneSignal                                                                        | Rescue campaign log + retention uplift                   |
| 24–27| 18 Jul – 15 Aug  | E-07    | Self-service advanced analytics (custom cohort builder + anomaly alerts)          | Analyst + DE              | 35                   | Non-tech users build complex cohorts (e.g., "high LTV but low D30 activity") in <2 min; auto-alerts on drops >10 %                                                                          | User demo video + alert log                              |
| 26–28| 01–22 Aug        | E-08    | Final uplift measurement + Phase E sign-off                                       | Finance + All             | 30                   | +18 % ARPU from personalization; ≥ 30 % total ROAS uplift vs 2025; finance-verified incremental profit $8–12 M in 2027 so far                                                              | Signed ROI report + champagne                            |
| 28   | 23–29 Aug        | E-09    | Phase E retrospective + hand-off to Phase F                                       | All                       | 10                   | Retro + lessons; Phase F (expansion/licensing) kick-off deck ready                                                                                                                         | Recording + sign-off                                     |

#### Phase F – Expansion & Licensing (Sep – Dec 2027)

**Goal**: Scale the platform beyond your studio — achieve cross-studio federation + launch white-label version for external revenue.  
By end of December 2027: $3–8 M ARR from licensing, platform supports 20+ titles across multiple studios, and you have a new revenue stream independent of game performance.

| Week | Dates 2027       | Task ID | Task (Jira title)                                                                 | Owner                     | Effort (person-days) | Acceptance Criteria (DoD) – Friday Demo                                                                                                                                                    | Deliverable / Proof                                      |
|------|------------------|---------|-----------------------------------------------------------------------------------|---------------------------|----------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------|
| 27–30| 29 Aug – 26 Sep  | F-01    | Cross-studio federation architecture + privacy-safe player ID stitching            | CTO + DE                  | 45                   | Single "Player 360" view across 20+ titles/studios; anonymized stitching (no PII shared); GDPR audit pass                                                                                 | Demo dashboard with multi-studio data                    |
| 28–32| 05 Sep – 03 Oct  | F-02    | Multi-tenant platform hardening (separate schemas, RBAC, billing hooks)            | DE + Security             | 50                   | 3+ internal studios onboarded seamlessly; role-based access (e.g., Studio A can't see Studio B raw data)                                                                                   | Onboarding playbook + live multi-tenant query            |
| 30–34| 19 Sep – 17 Oct  | F-03    | White-label product packaging (branding removal, custom domains, configurable UI)  | Product + Full-stack      | 55                   | External demo instance running with fictional branding; all studio-specific references stripped                                                                                         | Live white-label demo URL                                |
| 32–36| 03 Oct – 31 Oct  | F-04    | Sales enablement kit + pricing model (SaaS tiers: Basic, Pro, Enterprise)         | Product + Sales           | 40                   | Pitch deck, pricing page, contract templates; target ARR per customer $500 k–$2 M                                                                                                          | Sales kit PDF + mock contract                            |
| 34–38| 17 Oct – 14 Nov  | F-05    | First external pilot onboarding (2–3 partner studios)                             | Sales + DE                | 60                   | 2 external studios fully onboarded; their data flowing; LTV model adapted to their games; first invoice sent                                                                              | Partner testimonial + revenue dashboard                  |
| 36–40| 31 Oct – 28 Nov  | F-06    | Simulation App v5 – External "sandbox" mode for prospects                         | Full-stack + DS           | 45                   | Prospects get temporary access to spin up 1 M players with their own event schema — used in sales demos                                                                                   | Prospect demo recording + usage analytics                |
| 38–41| 14 Nov – 05 Dec  | F-07    | Scale to 5 paid customers + ARR run-rate tracking                                 | Sales + Finance           | 50                   | 5 signed contracts; $3–8 M ARR run-rate achieved; platform handling 10× current volume without performance degradation                                                                   | Signed contracts + ARR dashboard                         |
| 40–42| 28 Nov – 19 Dec  | F-08    | Platform governance for external users (SLA, support portal, usage monitoring)     | Ops + Legal               | 35                   | 99.9 % SLA defined; support portal live; automated usage alerts; external audit readiness                                                                                               | SLA doc + support portal link                            |
| 41–43| 05–31 Dec        | F-09    | Final 2027 impact audit + celebration + 2028 planning                             | All + Leadership          | 40                   | Total 2027 incremental profit from platform $20–30 M; licensing ARR confirmed; 2028 roadmap (AI innovation) approved                                                                      | Full-year ROI report + legendary end-of-year party        |
| 43   | 31 Dec           | F-10    | Phase F retrospective + hand-off to 2028                                          | All                       | 10                   | Retro + biggest celebration yet; platform now a standalone revenue-generating product                                                                                                     | Recording + champagne                                    |

### Phase G – Moonshots (2028–2030 and Beyond)  

**Goal**: Transcend traditional game studio economics — redefine player value, attention, and ownership using the platform as the core engine.  
This is no longer a roadmap of features.  
This is a **vision for rewriting the rules of interactive entertainment and human attention**.

| Year | Moonshot Title                          | Core Vision                                                                 | Key Milestones (2028–2030)                                                                                                                                                                                                 | Success Looks Like (by 2030)                                                                                   |
|------|-----------------------------------------|-----------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------|
| 2028 | **Player-Owned Value**                  | Players literally own a share of their lifetime value                      | • LTV-backed digital assets (utility-first tokens)<br>• "LTV Passport" — your predicted + realised value portable across all games<br>• Fractional whale staking pools<br>• First studio where players earn real yield on their playtime | First company in history where players are co-owners of revenue streams<br>Total player-owned value: $5–10 B locked |
| 2029 | **Autonomous Game Factory**             | The platform spins up profitable games without human creative input        | • Generative full-game engine (procedural narrative + balance + monetization)<br>• Simulation App runs 1,000× real-time — knows if a game will succeed before a single line of code is written<br>• 100+ AI-generated games launched, 90 %+ profitable | 50–200 profitable titles per year with near-zero failure rate<br>Studio becomes a "game venture fund" powered by AI |
| 2030 | **Attention Operating System**          | Own the routing and pricing of all human screen time (beyond gaming)       | • Global real-time attention marketplace<br>• Every minute of human attention priced by predicted lifetime value (games + social + streaming + work)<br>• Platform becomes neutral OS layer for all digital experiences | Company valuation $50–200 B<br>We no longer "make games" — we own and optimise the global economy of human attention |
